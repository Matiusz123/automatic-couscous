{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data represents house market information.\n",
    "# Expects the user to predict the market value of the property using a regression model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "outputs": [],
   "source": [
    "sc = SparkSession.builder.getOrCreate()\n",
    "train_path = 'house-prices-advanced-regression-techniques/train.csv'\n",
    "test_path = 'house-prices-advanced-regression-techniques/test.csv'\n",
    "train_data = sc.read.csv(train_path,header=True,inferSchema=True)\n",
    "test_data = sc.read.csv(test_path,header=True,inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# First I merge the train and test sets in order to do processing of both\n",
    "# The Results from the train set is saved in the target variable for later model creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "target = train_data.select('Id','SalePrice')\n",
    "train_data = train_data.drop('SalePrice')\n",
    "\n",
    "data = DataFrame.unionAll(train_data, test_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# First we need to replace the values of certain columns because the value 'NA' actually means something so we replace it with '0'\n",
    "# All the data is explained in the data_description.txt file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "for column in [\n",
    "    'Alley',\n",
    "    'BsmtQual',\n",
    "    'BsmtCond',\n",
    "    'BsmtExposure',\n",
    "    'BsmtFinType1',\n",
    "    'BsmtFinType2',\n",
    "    'FireplaceQu',\n",
    "    'GarageType',\n",
    "    'GarageFinish',\n",
    "    'GarageQual',\n",
    "    'GarageCond',\n",
    "    'PoolQC',\n",
    "    'Fence',\n",
    "    'MiscFeature'\n",
    "]:\n",
    "    data = data.withColumn(column, regexp_replace(column, 'NA', '0'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Next step is to replace all the missing values that don't mean anything\n",
    "# with an average value from each column,\n",
    "# also I'm not sure why the columns changed it;'s type, so let's change them back to desired type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, col\n",
    "from pyspark.sql.types import IntegerType\n",
    "for column in ['LotFrontage','MasVnrArea',\n",
    "                      'BsmtFinSF1','BsmtFinSF2',\n",
    "                      'BsmtUnfSF', 'TotalBsmtSF',\n",
    "                      'BsmtFullBath', 'GarageYrBlt',\n",
    "                      'BsmtHalfBath', 'GarageCars']:\n",
    "    me = data.select(mean(col(column)).alias('avg')).collect()[0]['avg']\n",
    "    me = str(int(me))\n",
    "    data = data.withColumn(column, regexp_replace(column, 'NA', me))\n",
    "    data = data.withColumn(column,col(column).cast(IntegerType()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Filling all the missing values with the mean values of each column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "outputs": [],
   "source": [
    "for column, types in data.dtypes:\n",
    "    if types == 'int':\n",
    "        me = data.select(mean(col(column)).alias('avg')).collect()[0]['avg']\n",
    "        me = int(me)\n",
    "        data.na.fill(value=me,subset=[column])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now we aggregate to find out the count of missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "outputs": [
    {
     "data": {
      "text/plain": "   Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n0   0           0         0            0        0       0      0         0   \n\n   LandContour  Utilities  ...  ScreenPorch  PoolArea  PoolQC  Fence  \\\n0            0          0  ...            0         0       0      0   \n\n   MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n0            0        0       0       0         0              0  \n\n[1 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 80 columns</p>\n</div>"
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, when, isnan\n",
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).toPandas()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now let's perform 3 aggregations with the preprocessed data\n",
    "# Aggregations :\n",
    "# - Find average Year of property on the market \"YearBuilt\"\n",
    "# - Find mean Lot Area \"LotArea\"\n",
    "# - Find skewness of Total square feet of basement area \"TotalBsmtSF\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Year of property on the market: 1971.3127783487496\n",
      "Mean Lot Area: 10168.11408016444\n",
      "Skewness of Total square feet of basement area: 1.1624855612191176\n",
      "Dataframe aggregations performed in 0.3689737319946289 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, mean, skewness\n",
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "print(\"Average Year of property on the market: \" + str(data.select(avg(\"YearBuilt\")).collect()[0][0]))\n",
    "print(\"Mean Lot Area: \" + str(data.select(mean(\"LotArea\")).collect()[0][0]))\n",
    "print(\"Skewness of Total square feet of basement area: \" + str(data.select(skewness(\"TotalBsmtSF\")).collect()[0][0]))\n",
    "\n",
    "print(\"Dataframe aggregations performed in \" + str(time() - t0) + \" seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now let's perform 2 different aggregations with the preprocessed data using groupBy\n",
    "# Aggregations :\n",
    "# - Find max Lot Area \"LotArea\" for each type of \"MSZoning\": Identifies the general zoning classification of the sale.\n",
    "# - Find sum of area connected to the street \"LotFrontage\" for each type of \"Neighborhood\": Physical locations within Ames city limits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|MSZoning|max(LotArea)|\n",
      "+--------+------------+\n",
      "| C (all)|       18000|\n",
      "|      RH|       12155|\n",
      "|      FV|       13162|\n",
      "|      RL|      215245|\n",
      "|      RM|       33120|\n",
      "|      NA|       56600|\n",
      "+--------+------------+\n",
      "\n",
      "+------------+----------------+\n",
      "|Neighborhood|sum(LotFrontage)|\n",
      "+------------+----------------+\n",
      "|     Veenker|            1704|\n",
      "|     BrkSide|            6197|\n",
      "|     NPkVill|             729|\n",
      "|     NridgHt|           13929|\n",
      "|     NoRidge|            6121|\n",
      "|      NWAmes|           10103|\n",
      "|     OldTown|           14837|\n",
      "|     Gilbert|           11963|\n",
      "|     Somerst|           11837|\n",
      "|     Crawfor|            7186|\n",
      "|       NAmes|           32896|\n",
      "|      IDOTRR|            5829|\n",
      "|     Edwards|           13014|\n",
      "|      Sawyer|           10963|\n",
      "|     StoneBr|            3205|\n",
      "|     CollgCr|           18937|\n",
      "|       SWISU|            2875|\n",
      "|     MeadowV|            1121|\n",
      "|      Timber|            5661|\n",
      "|     Blmngtn|            1490|\n",
      "+------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "SQL dataframe aggregations with groupby performed in 0.6900548934936523 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "data.groupby('MSZoning').max().select('MSZoning','max(LotArea)').show()\n",
    "data.groupby('Neighborhood').sum().select('Neighborhood','sum(LotFrontage)').show()\n",
    "\n",
    "print(\"SQL dataframe aggregations with groupby performed in \" + str(time() - t0) + \" seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateusz/Library/Python/3.9/lib/python/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "data.createOrReplaceTempView(\"sql_table\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL aggregations with groupby performed in 0.5405409336090088 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "sqlContext.sql('''SELECT MAX(LotArea), MSZoning FROM sql_table GROUP BY MSZoning''').collect()\n",
    "sqlContext.sql('''SELECT SUM(LotFrontage), Neighborhood FROM sql_table GROUP BY Neighborhood''').collect()\n",
    "\n",
    "print(\"SQL aggregations with groupby performed in \" + str(time() - t0) + \" seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
